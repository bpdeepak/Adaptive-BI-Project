{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4769928",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data loaded:\n",
      "Empty DataFrame\n",
      "Columns: [order_id, quantity, unit_price, total_value, category, location]\n",
      "Index: []\n",
      "\n",
      "üìä Summary statistics:\n",
      "       order_id quantity unit_price total_value category location\n",
      "count         0        0          0           0        0        0\n",
      "unique        0        0          0           0        0        0\n",
      "top         NaN      NaN        NaN         NaN      NaN      NaN\n",
      "freq        NaN      NaN        NaN         NaN      NaN      NaN\n",
      "\n",
      "üîç Null values per column:\n",
      "order_id       0\n",
      "quantity       0\n",
      "unit_price     0\n",
      "total_value    0\n",
      "category       0\n",
      "location       0\n",
      "dtype: int64\n",
      "‚ö†Ô∏è Warning: DataFrame is empty after loading or cleaning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_155018/2659739295.py:31: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Connect to PostgreSQL\n",
    "conn = psycopg2.connect(\n",
    "    dbname=\"adaptive_bi\",\n",
    "    user=\"bi_user\",\n",
    "    password=\"bi_pass\",\n",
    "    host=\"localhost\",\n",
    "    port=\"5432\"\n",
    ")\n",
    "\n",
    "# Query: join orders, products, customers\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    o.order_id::text,              -- Cast UUID to text (optional)\n",
    "    o.quantity, \n",
    "    o.price AS unit_price, \n",
    "    o.price * o.quantity AS total_value,\n",
    "    p.category, \n",
    "    c.location\n",
    "FROM orders o\n",
    "JOIN products p ON o.product_id = p.product_id\n",
    "JOIN customers c ON o.customer_id = c.customer_id\n",
    "\"\"\"\n",
    "\n",
    "# Load data\n",
    "df = pd.read_sql(query, conn)\n",
    "print(\"‚úÖ Data loaded:\")\n",
    "print(df.head())\n",
    "\n",
    "# Basic statistics\n",
    "print(\"\\nüìä Summary statistics:\")\n",
    "print(df.describe())\n",
    "\n",
    "# Null value check\n",
    "print(\"\\nüîç Null values per column:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Optional: drop rows with nulls for modeling\n",
    "df = df.dropna()\n",
    "\n",
    "# Visualize distributions safely\n",
    "if not df.empty:\n",
    "    sns.histplot(df['quantity'], bins=20, kde=False)\n",
    "    plt.title('Quantity Distribution')\n",
    "    plt.show()\n",
    "\n",
    "    sns.histplot(df['unit_price'], bins=20, kde=False)\n",
    "    plt.title('Unit Price Distribution')\n",
    "    plt.show()\n",
    "\n",
    "    sns.histplot(df['total_value'], bins=20, kde=False)\n",
    "    plt.title('Total Order Value Distribution')\n",
    "    plt.show()\n",
    "\n",
    "    # Correlation heatmap\n",
    "    corr = df[['quantity', 'unit_price', 'total_value']].corr()\n",
    "    sns.heatmap(corr, annot=True, cmap='coolwarm')\n",
    "    plt.title('Feature Correlation Heatmap')\n",
    "    plt.show()\n",
    "\n",
    "    # Encode categorical variables\n",
    "    df_encoded = pd.get_dummies(df, columns=['category', 'location'], drop_first=True)\n",
    "\n",
    "    # Feature importance with RandomForest\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "    X = df_encoded.drop(['order_id', 'total_value'], axis=1)\n",
    "    y = df_encoded['total_value']\n",
    "\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    model.fit(X, y)\n",
    "\n",
    "    # Get feature importances\n",
    "    importances = model.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "\n",
    "    # Plot feature importances\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.title('Feature Importances')\n",
    "    plt.bar(range(X.shape[1]), importances[indices], align='center')\n",
    "    plt.xticks(range(X.shape[1]), X.columns[indices], rotation=90)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"‚úÖ Feature exploration complete!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Warning: DataFrame is empty after loading or cleaning.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867875c6-f76f-4b07-ac4c-fbad839fed6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
